{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1T1\n",
    "import csv\n",
    "\n",
    "def read_csv_files(file_names):\n",
    "    all_texts = []\n",
    "    for file_name in file_names:\n",
    "        with open(file_name, 'r') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                all_texts.append(row['text'])\n",
    "    return all_texts\n",
    "\n",
    "def write_to_txt_file(all_texts, output_file):\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for text in all_texts:\n",
    "            outfile.write(text + '\\n')\n",
    "\n",
    "csv_file_names = ['CSV1.csv', 'CSV2.csv', 'CSV3.csv', 'CSV4.csv']\n",
    "all_texts = read_csv_files(csv_file_names)\n",
    "write_to_txt_file(all_texts, 'Assigment2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1T2\n",
    "\n",
    "pip install spacy\n",
    "pip install scispacy\n",
    "pip install en_core_sci_sm\n",
    "pip install en_ner_bc5cdr_md\n",
    "pip install transformers\n",
    "pip install biobert-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1T3.1\n",
    "import collections\n",
    "\n",
    "def count_word_occurrences(text):\n",
    "    word_tokenizer = spacy.lang.en.English().Defaults.create_tokenizer()\n",
    "    words = word_tokenizer(text)\n",
    "    word_counts = collections.Counter(words)\n",
    "    return word_counts\n",
    "\n",
    "with open('Assigment2.txt', 'r') as infile:\n",
    "    all_texts = infile.readlines()\n",
    "\n",
    "word_counts = {}\n",
    "for text in all_texts:\n",
    "    counts = count_word_occurrences(text)\n",
    "    for word, count in counts.items():\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += count\n",
    "        else:\n",
    "            word_counts[word] = count\n",
    "\n",
    "top_30_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:30]\n",
    "\n",
    "with open('Assigment2.csv', 'w') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['word', 'count'])\n",
    "    for word, count in top_30_words:\n",
    "        writer.writerow([word, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1T3.2\n",
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "import operator\n",
    "\n",
    "def count_unique_tokens(file_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    cleaned_text = re.sub(r'\\W+', ' ', text).lower()\n",
    "    tokens = tokenizer.tokenize(cleaned_text)\n",
    "    filtered_tokens = [token.lower() for token in tokens if token.isalnum()]\n",
    "    token_counts = {}\n",
    "    for token in filtered_tokens:\n",
    "        if token in token_counts:\n",
    "            token_counts[token] += 1\n",
    "        else:\n",
    "            token_counts[token] = 1\n",
    "\n",
    "    top_30_words = sorted(token_counts.items(), key=operator.itemgetter(1), reverse=True)[:30]\n",
    "\n",
    "    return top_30_words\n",
    "\n",
    "file_path = \"Assigment2.txt\"\n",
    "result = count_unique_tokens(file_path)\n",
    "\n",
    "print(\"Top 30 unique tokens:\")\n",
    "for word, count in result:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1T4\n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "\n",
    "def extract_entities_spacy(model_name, file_path):\n",
    "    nlp = spacy.load(model_name)\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    doc = nlp(text)\n",
    "    diseases = [ent.text for ent in doc.ents if ent.label_ == 'DIS']\n",
    "    drugs = [ent.text for ent in doc.ents if ent.label_ == 'DRU']\n",
    "    return diseases, drugs\n",
    "\n",
    "def extract_entities_biobert(file_path):\n",
    "    ner = pipeline('ner', model='dmis-lab/biobert-v1.1-adequacy', tokenizer='dmis-lab/biobert-v1.1-adequacy')\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    doc = ner(text)\n",
    "    diseases = [ent['word'] for ent in doc if ent['entity'] == 'DISEASE']\n",
    "    drugs = [ent['word'] for ent in doc if ent['entity'] == 'CHEMICAL']\n",
    "    return diseases, drugs\n",
    "\n",
    "file_path = 'Assigment2.txt'\n",
    "\n",
    "spacy_diseases, spacy_drugs = extract_entities_spacy('en_ner_bc5cdr_md', file_path)\n",
    "\n",
    "biobert_diseases, biobert_drugs = extract_entities_biobert(file_path)\n",
    "\n",
    "def compare_results(spacy_results, biobert_results):\n",
    "    total_spacy_entities = len(spacy_results[0]) + len(spacy_results[1])\n",
    "    total_biobert_entities = len(biobert_results[0]) + len(biobert_results[1])\n",
    "\n",
    "    print(\"Total entities detected by spaCy:\", total_spacy_entities)\n",
    "    print(\"Total entities detected by BioBERT:\", total_biobert_entities)\n",
    "\n",
    "    common_diseases = list(set(spacy_diseases) & set(biobert_diseases))\n",
    "    common_drugs = list(set(spacy_drugs) & set(biobert_drugs))\n",
    "\n",
    "    print(\"\\nCommon diseases detected by both models:\", common_diseases)\n",
    "    print(\"Common drugs detected by both models:\", common_drugs)\n",
    "\n",
    "    print(\"\\nMost common diseases detected by spaCy:\", most_common(spacy_diseases))\n",
    "    print(\"Most common diseases detected by BioBERT:\", most_common(biobert_diseases))\n",
    "    print(\"Most common drugs detected by spaCy:\", most_common(spacy_drugs))\n",
    "    print(\"Most common drugs detected by BioBERT:\", most_common(biobert_drugs))\n",
    "\n",
    "def most_common(lst):\n",
    "    return Counter(lst).most_common()\n",
    "\n",
    "compare_results((spacy_diseases, spacy_drugs), (biobert_diseases, biobert_drugs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2C1\n",
    "import time\n",
    "current_time= int(time.time())\n",
    "generated_number= (current_time%100)+50\n",
    "if(generated_number%2==0)\n",
    "    generated_number+=10\n",
    "\n",
    "from PIL import Image\n",
    "def generate_chapter1out(generated_number):\n",
    "    original_image = Image.open('Chapter1.png')\n",
    "    new_image = Image.new('RGB', original_image.size)\n",
    "    for i in range(original_image.width):\n",
    "        for j in range(original_image.height):\n",
    "            r, g, b = original_image.getpixel((i, j))\n",
    "            new_r = min(255, r + generated_number)\n",
    "            new_g = min(255, g + generated_number)\n",
    "            new_b = min(255, b + generated_number)\n",
    "            new_image.putpixel((i, j), (new_r, new_g, new_b))\n",
    "    new_image.save('chapter1out.png')\n",
    "    red_sum = sum(new_image.getpixel((i, j))[0] for i in range(new_image.width) for j in range(new_image.height))\n",
    "\n",
    "    return red_sum\n",
    "generate_chapter1out(generated_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number String: 561984235270145785310\n",
      "Letter String: aAwwsktraYmnssfsqD\n",
      "Even Numbers in Number String: 684220480\n",
      "Uppercase Letters in Letter String: AYD\n",
      "ASCII Code Decimal Values of Even Numbers: 54 56 52 50 50 48 52 56 48 \n",
      "ASCII Code Decimal Values of Uppercase Letters: 65 89 68 \n",
      "No valid shift key found.\n"
     ]
    }
   ],
   "source": [
    "#Q2C2\n",
    "def separate_numbers_letters(s):\n",
    "    numbers = \"\"\n",
    "    letters = \"\"\n",
    "    for char in s:\n",
    "        if char.isdigit():\n",
    "            numbers += char\n",
    "        else:\n",
    "            letters += char\n",
    "    return numbers, letters\n",
    "\n",
    "def convert_even_numbers(s):\n",
    "    even_numbers = \"\"\n",
    "    for char in s:\n",
    "        if int(char) % 2 == 0:\n",
    "            even_numbers += char\n",
    "    return even_numbers\n",
    "\n",
    "def convert_uppercase_letters(s):\n",
    "    uppercase_letters = \"\"\n",
    "    for char in s:\n",
    "        if char.isupper():\n",
    "            uppercase_letters += char\n",
    "    return uppercase_letters\n",
    "\n",
    "def convert_to_ascii(s):\n",
    "    ascii_codes = \"\"\n",
    "    for char in s:\n",
    "        ascii_codes += str(ord(char)) + \" \"\n",
    "    return ascii_codes\n",
    "\n",
    "s = '56aAww1984sktr235270aYmn145ss785fsq31D0'\n",
    "\n",
    "numbers, letters = separate_numbers_letters(s)\n",
    "even_numbers = convert_even_numbers(numbers)\n",
    "uppercase_letters = convert_uppercase_letters(letters)\n",
    "\n",
    "even_numbers_ascii = convert_to_ascii(even_numbers)\n",
    "uppercase_letters_ascii = convert_to_ascii(uppercase_letters)\n",
    "\n",
    "print(\"Number String:\", numbers)\n",
    "print(\"Letter String:\", letters)\n",
    "print(\"Even Numbers in Number String:\", even_numbers)\n",
    "print(\"Uppercase Letters in Letter String:\", uppercase_letters)\n",
    "print(\"ASCII Code Decimal Values of Even Numbers:\", even_numbers_ascii)\n",
    "print(\"ASCII Code Decimal Values of Uppercase Letters:\", uppercase_letters_ascii)\n",
    "\n",
    "import string\n",
    "\n",
    "def decrypt_quote(quote, shift):\n",
    "    decrypted_quote = \"\"\n",
    "    for char in quote:\n",
    "        if char.isalpha():\n",
    "            if char.isupper():\n",
    "                decrypted_quote += string.ascii_uppercase[(string.ascii_uppercase.index(char) - shift) % 26]\n",
    "            else:\n",
    "                decrypted_quote += string.ascii_lowercase[(string.ascii_lowercase.index(char) - shift) % 26]\n",
    "        else:\n",
    "            decrypted_quote += char\n",
    "    return decrypted_quote\n",
    "\n",
    "def find_shift_key(cryptogram, original_quote):\n",
    "    for shift in range(1, 26):\n",
    "        decrypted_quote = decrypt_quote(cryptogram, shift)\n",
    "        if decrypted_quote.strip() == original_quote:\n",
    "            return shift\n",
    "    return None\n",
    "\n",
    "cryptogram = \"VZ FRYSVFU VZCNGVRAG NAQ N YVGGYR VAFRPHER V ZNXR ZVFGNXRF V NZ BHG BS PBAGEBY NAQNG GVZRF UNEQ GB UNAQYR OHG VS LBH PNAG UNAQYR ZR NG ZL JBEFG GURA LBH FHER NF URYYQBAG QRFREIR ZR NG ZL ORFG ZNEVYLA ZBAEBR\"\n",
    "original_quote = \"Hamlet's Act 3, Scene 1, Hamlet says 'To be, or not to be: that is the question.'\"\n",
    "\n",
    "shift_key = find_shift_key(cryptogram, original_quote)\n",
    "if shift_key is not None:\n",
    "    print(f\"The shift key is {shift_key}.\")\n",
    "    decrypted_quote = decrypt_quote(cryptogram, shift_key)\n",
    "    print(f\"The original quote is '{decrypted_quote}'.\")\n",
    "else:\n",
    "    print(\"No valid shift key found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted Code: q y } }}\n",
      "Decrypted Code: Y a } }}\n",
      "Total: -15\n"
     ]
    }
   ],
   "source": [
    "# Fixing the encryption function and explaining errors with comments\n",
    "\n",
    "def encrypt(text, key):\n",
    "    encrypted_text = \"\"\n",
    "    for char in text:\n",
    "        if char.isalpha():\n",
    "            shifted = ord(char) + key  # Assign 'shifted' to the shifted character\n",
    "            if char.islower():\n",
    "                if shifted > ord('z'):\n",
    "                    shifted -= 26\n",
    "                elif shifted < ord('a'):\n",
    "                    shifted += 26\n",
    "            elif char.isupper():\n",
    "                if shifted > ord('Z'):\n",
    "                    shifted -= 26\n",
    "                elif shifted < ord('A'):\n",
    "                    shifted += 26\n",
    "            encrypted_text += chr(shifted)  # Correct indentation\n",
    "        else:\n",
    "            encrypted_text += char\n",
    "    return encrypted_text\n",
    "\n",
    "# Fixing and explaining errors in the code\n",
    "tybony_inevnoyr = 100  # Define 'tybony_inevnoyr'\n",
    "zl_qvpg = {\"xrl1\": \"inyhr1\", \"xrl2\": \"inyhr2\", \"xrl3\": \"inyhr3\"}  # Correct key-value pairs\n",
    "\n",
    "def cebprff_ahzoref(ahzoref):\n",
    "    tybony = tybony_inevnoyr  # Assign 'tybony' correctly\n",
    "    ybpny_inevnoyr = 5\n",
    "    result = []  # Create an empty list for the result\n",
    "    while ybpny_inevnoyr > 0:\n",
    "        if ybpny_inevnoyr % 2 == 0:  # Correct comparison operator\n",
    "            result.insert(0, ybpny_inevnoyr)  # Correct function name and append to 'result'\n",
    "        ybpny_inevnoyr -= 1\n",
    "    return result  # Return the 'result' list\n",
    "\n",
    "zl_frg = (1, 2, 3, 4, 5, 5, 4, 3, 2, 1)\n",
    "\n",
    "def zbqvsl_qvpg(ybpry_inevnoyr):\n",
    "    ybpny_inevnoyr = 10  # Assign 'ybpny_inevnoyr' correctly\n",
    "    zl_frg = {\"xrl4\": ybpny_inevnoyr}  # Use 'zl_frg' dictionary correctly\n",
    "\n",
    "def hcgngr_tybony():\n",
    "    global tybony_inevnoyr  # Use global correctly\n",
    "    tybony_inevnoyr += 10\n",
    "    for v in range(5):\n",
    "        print(v)  # Correct indentation\n",
    "\n",
    "# Key calculation\n",
    "total = 100  # Define 'total' correctly\n",
    "key = total // 2  # Correct calculation, use '//' for integer division\n",
    "\n",
    "# Decryption function\n",
    "def decrypt(encrypted_text, key):\n",
    "    decrypted_text = \"\"\n",
    "    for char in encrypted_text:\n",
    "        if char.isalpha():\n",
    "            shifted = ord(char) - key\n",
    "            if char.islower():\n",
    "                if shifted > ord('z'):\n",
    "                    shifted -= 26\n",
    "                elif shifted < ord('a'):\n",
    "                    shifted += 26\n",
    "            elif char.isupper():\n",
    "                if shifted > ord('Z'):\n",
    "                    shifted -= 26\n",
    "                elif shifted < ord('A'):\n",
    "                    shifted += 26\n",
    "            decrypted_text += chr(shifted)\n",
    "        else:\n",
    "            decrypted_text += char\n",
    "    return decrypted_text\n",
    "\n",
    "# Printing results\n",
    "original_code = \"Your original text here\"  # Replace with original text\n",
    "encrypted_code = encrypt(original_code, key)\n",
    "print(\"Encrypted Code:\", encrypted_code)\n",
    "\n",
    "decrypted_code = decrypt(encrypted_code, key)\n",
    "print(\"Decrypted Code:\", decrypted_code)\n",
    "\n",
    "total = 0  # Reset 'total' to 0\n",
    "for i in range(5):\n",
    "    for j in range(3):\n",
    "        if i * j == 5:  # Correct operator '*', not 'x'\n",
    "            total += i + j\n",
    "        else:\n",
    "            total -= i - j\n",
    "print(\"Total:\", total)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
